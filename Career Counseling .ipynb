{"metadata": {"kernelspec": {"name": "python3", "display_name": "Python 3.11", "language": "python"}, "language_info": {"name": "python", "version": "3.11.13", "mimetype": "text/x-python", "codemirror_mode": {"name": "ipython", "version": 3}, "pygments_lexer": "ipython3", "nbconvert_exporter": "python", "file_extension": ".py"}}, "nbformat_minor": 4, "nbformat": 4, "cells": [{"cell_type": "markdown", "source": "![image](https://raw.githubusercontent.com/IBM/watson-machine-learning-samples/master/cloud/notebooks/headers/watsonx-Prompt_Lab-Notebook.png)\n# AI Service Deployment Notebook\nThis notebook contains steps and code to test, promote, and deploy an Agent as an AI Service.\n\n**Note:** Notebook code generated using Agent Lab will execute successfully.\nIf code is modified or reordered, there is no guarantee it will successfully execute.\nFor details, see: <a href=\"/docs/content/wsj/analyze-data/fm-prompt-save.html?context=wx\" target=\"_blank\">Saving your work in Agent Lab as a notebook.</a>\n\n\nSome familiarity with Python is helpful. This notebook uses Python 3.11.\n\n## Contents\nThis notebook contains the following parts:\n\n1. Setup\n2. Initialize all the variables needed by the AI Service\n3. Define the AI service function\n4. Deploy an AI Service\n5. Test the deployed AI Service\n\n## 1. Set up the environment\n\nBefore you can run this notebook, you must perform the following setup tasks:", "metadata": {}}, {"cell_type": "markdown", "source": "### Connection to WML\nThis cell defines the credentials required to work with watsonx API for both the execution in the project, \nas well as the deployment and runtime execution of the function.\n\n**Action:** Provide the IBM Cloud personal API key. For details, see\n<a href=\"https://cloud.ibm.com/docs/account?topic=account-userapikey&interface=ui\" target=\"_blank\">documentation</a>.\n", "metadata": {}}, {"cell_type": "code", "source": "import os\nfrom ibm_watsonx_ai import APIClient, Credentials\nimport getpass\n\ncredentials = Credentials(\n    url=\"https://eu-gb.ml.cloud.ibm.com\",\n    api_key=getpass.getpass(\"Please enter your api key (hit enter): \")\n)\n\n", "metadata": {"id": "5c66d437-2eb3-453b-8305-bee3b92f1ef2"}, "outputs": [{"output_type": "stream", "name": "stdin", "text": "Please enter your api key (hit enter):  \u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\n"}], "execution_count": 15}, {"cell_type": "code", "source": "client = APIClient(credentials)", "metadata": {"id": "bd672db2-d3f8-40cc-a3ff-60950543bd47"}, "outputs": [], "execution_count": 16}, {"cell_type": "markdown", "source": "### Connecting to a space\nA space will be be used to host the promoted AI Service.\n", "metadata": {}}, {"cell_type": "code", "source": "space_id = \"07e9c7d9-bb6e-49e4-8503-94d090a24a86\"\nclient.set.default_space(space_id)\n", "metadata": {"id": "281c4187-6c4b-4164-901e-c7f38d0ccd1b"}, "outputs": [{"execution_count": 17, "output_type": "execute_result", "data": {"text/plain": "'SUCCESS'"}, "metadata": {}}], "execution_count": 17}, {"cell_type": "markdown", "source": "### Promote asset(s) to space\nWe will now promote assets we will need to stage in the space so that we can access their data from the AI service.\n", "metadata": {}}, {"cell_type": "code", "source": "source_project_id = \"1f760c18-c2a4-429d-9a92-cdc7d273939e\"\n", "metadata": {"id": "aeef2e0e-d001-4d01-9dde-8bcf43cf2526"}, "outputs": [], "execution_count": 18}, {"cell_type": "markdown", "source": "## 2. Create the AI service function\nWe first need to define the AI service function\n\n### 2.1 Define the function", "metadata": {}}, {"cell_type": "code", "source": "params = {\n    \"space_id\": \"<YOUR_SPACE_ID>\"\n}\n\ndef gen_ai_service(context, params=params, **custom):\n    from langchain_ibm import ChatWatsonx\n    from ibm_watsonx_ai import APIClient\n    from ibm_watsonx_ai.foundation_models.utils import Tool, Toolkit\n    from langchain_core.messages import AIMessage, HumanMessage\n    from langgraph.checkpoint.memory import MemorySaver\n    from langgraph.prebuilt import create_react_agent\n\n    model_id = \"meta-llama/llama-3-3-70b-instruct\"\n    service_url = \"https://eu-gb.ml.cloud.ibm.com\"\n\n    # Credentials\n    credentials = {\n        \"url\": service_url,\n        \"token\": context.generate_token()\n    }\n    client = APIClient(credentials)\n\n    space_id = params.get(\"space_id\")\n    if not space_id:\n        raise ValueError(\"space_id is required\")\n    client.set.default_space(space_id)\n\n    # Create chat model\n    def create_chat_model(watsonx_client):\n        parameters = {\n            \"frequency_penalty\": 0,\n            \"max_tokens\": 1000,\n            \"presence_penalty\": 0,\n            \"temperature\": 0,\n            \"top_p\": 1\n        }\n        return ChatWatsonx(\n            model_id=model_id,\n            url=service_url,\n            space_id=space_id,\n            params=parameters,\n            watsonx_client=watsonx_client,\n        )\n\n    # Utility tool wrapper\n    def create_utility_agent_tool(tool_name, config, api_client, **kwargs):\n        from langchain_core.tools import StructuredTool\n        utility_agent_tool = Toolkit(api_client=api_client).get_tool(tool_name)\n        tool_description = kwargs.get(\"tool_description\") or utility_agent_tool.get(\"agent_description\") or utility_agent_tool.get(\"description\")\n\n        tool_schema = utility_agent_tool.get(\"input_schema\") or {\n            \"type\": \"object\",\n            \"additionalProperties\": False,\n            \"$schema\": \"http://json-schema.org/draft-07/schema#\",\n            \"properties\": {\n                \"input\": {\n                    \"description\": \"input for the tool\",\n                    \"type\": \"string\"\n                }\n            }\n        }\n\n        def run_tool(**tool_input):\n            query = tool_input if utility_agent_tool.get(\"input_schema\") else tool_input.get(\"input\")\n            results = utility_agent_tool.run(input=query, config=config)\n            return results.get(\"output\")\n\n        return StructuredTool(\n            name=tool_name,\n            description=tool_description,\n            func=run_tool,\n            args_schema=tool_schema\n        )\n\n    # Create tools\n    def create_tools(inner_client):\n        tools = []\n        tools.append(create_utility_agent_tool(\"GoogleSearch\", None, inner_client))\n        tools.append(create_utility_agent_tool(\"Wikipedia\", {\"maxResults\": 5}, inner_client))\n        tools.append(create_utility_agent_tool(\"DuckDuckGo\", {}, inner_client))\n        return tools\n\n    # Create agent\n    def create_agent(model, tools, messages):\n        memory = MemorySaver()\n        instructions = \"\"\"You are a helpful AI career counseling assistant.\nStudents often struggle to make informed career decisions...\nThe challenge is to develop an intelligent, autonomous agent that monitors student performance, interests, and labor trends to deliver tailored career suggestions.\n\"\"\"\n        for message in messages:\n            if message[\"role\"] == \"system\":\n                instructions += \"\\n\" + message[\"content\"]\n\n        return create_react_agent(model, tools=tools, checkpointer=memory, state_modifier=instructions)\n\n    # Convert chat messages\n    def convert_messages(messages):\n        converted = []\n        for message in messages:\n            if message[\"role\"] == \"user\":\n                converted.append(HumanMessage(content=message[\"content\"]))\n            elif message[\"role\"] == \"assistant\":\n                converted.append(AIMessage(content=message[\"content\"]))\n        return converted\n\n    # Generate function\n    def generate(context):\n        payload = context.get_json()\n        messages = payload.get(\"messages\")\n        inner_client = APIClient({\"url\": service_url, \"token\": context.get_token()})\n        model = create_chat_model(inner_client)\n        tools = create_tools(inner_client)\n        agent = create_agent(model, tools, messages)\n\n        generated_response = agent.invoke(\n            {\"messages\": convert_messages(messages)},\n            {\"configurable\": {\"thread_id\": \"42\"}}\n        )\n\n        last_message = generated_response[\"messages\"][-1].content\n        return {\n            \"headers\": {\"Content-Type\": \"application/json\"},\n            \"body\": {\"choices\": [{\"index\": 0, \"message\": {\"role\": \"assistant\", \"content\": last_message}}]}\n        }\n\n    # Streaming function\n    def generate_stream(context):\n        payload = context.get_json()\n        messages = payload.get(\"messages\")\n        inner_client = APIClient({\"url\": service_url, \"token\": context.get_token()})\n        model = create_chat_model(inner_client)\n        tools = create_tools(inner_client)\n        agent = create_agent(model, tools, messages)\n\n        for chunk in agent.stream(\n            {\"messages\": convert_messages(messages)},\n            {\"configurable\": {\"thread_id\": \"42\"}},\n            stream_mode=[\"updates\", \"messages\"]\n        ):\n            yield chunk\n\n    return generate, generate_stream\n", "metadata": {"id": "2e0ae2f4-8867-4ec8-a63c-6ea9f0db22e7"}, "outputs": [], "execution_count": 19}, {"cell_type": "markdown", "source": "### 2.2 Test locally", "metadata": {}}, {"cell_type": "code", "source": "# Initialize AI Service function locally\nfrom ibm_watsonx_ai.deployments import RuntimeContext\n\ncontext = RuntimeContext(api_client=client)\n\nstreaming = False\nfindex = 1 if streaming else 0\n\n# Pass space_id in params dict\nlocal_function = gen_ai_service(context, params={\"space_id\": space_id})[findex]\n\n# Example empty messages list\nmessages = []\n", "metadata": {"id": "277dac63-7f2e-464c-a1d6-da10a241446d"}, "outputs": [], "execution_count": 20}, {"cell_type": "code", "source": "local_question = \"Change this question to test your function\"\n\nmessages.append({ \"role\" : \"user\", \"content\": local_question })\n\ncontext = RuntimeContext(api_client=client, request_payload_json={\"messages\": messages})\n\nresponse = local_function(context)\n\nresult = ''\n\nif (streaming):\n    for chunk in response:\n        print(chunk, end=\"\\n\\n\", flush=True)\nelse:\n    print(response)\n", "metadata": {"id": "778f26d3-6a4b-4a5e-860c-72cc5376aae2"}, "outputs": [{"name": "stderr", "text": "Failure during Get available foundation models. (GET https://eu-gb.ml.cloud.ibm.com/ml/v1/foundation_model_specs?version=2025-07-09&space_id=07e9c7d9-bb6e-49e4-8503-94d090a24a86&filters=function_text_generation%2C%21lifecycle_withdrawn%3Aand&limit=200)\nStatus code: 403, body: {\"errors\":[{\"code\":\"no_associated_service_instance_error\",\"message\":\"space_id 07e9c7d9-bb6e-49e4-8503-94d090a24a86 is not associated with a WML instance\",\"more_info\":\"https://cloud.ibm.com/apidocs/watsonx-ai#list-foundation-model-specs\"}],\"trace\":\"38fb913e034eadea849bf9f28b57bc10\",\"status_code\":403}\nUnable to get model specifications from url: https://eu-gb.ml.cloud.ibm.com\nReason: Failure during Get available foundation models. (GET https://eu-gb.ml.cloud.ibm.com/ml/v1/foundation_model_specs?version=2025-07-09&space_id=07e9c7d9-bb6e-49e4-8503-94d090a24a86&filters=function_text_generation%2C%21lifecycle_withdrawn%3Aand&limit=200)\nStatus code: 403, body: {\"errors\":[{\"code\":\"no_associated_service_instance_error\",\"message\":\"space_id 07e9c7d9-bb6e-49e4-8503-94d090a24a86 is not associated with a WML instance\",\"more_info\":\"https://cloud.ibm.com/apidocs/watsonx-ai#list-foundation-model-specs\"}],\"trace\":\"38fb913e034eadea849bf9f28b57bc10\",\"status_code\":403}\n", "output_type": "stream"}, {"traceback": ["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m", "\u001b[0;31mApiRequestFailure\u001b[0m                         Traceback (most recent call last)", "File \u001b[0;32m/opt/conda/envs/Python-RT24.1/lib/python3.11/site-packages/ibm_watsonx_ai/foundation_models_manager.py:94\u001b[0m, in \u001b[0;36mFoundationModelsManager._get_spec\u001b[0;34m(self, url, operation_name, error_msg_id, model_id, limit, filters, asynchronous, get_all, tech_preview)\u001b[0m\n\u001b[1;32m     93\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 94\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_with_or_without_limit(\n\u001b[1;32m     95\u001b[0m             url\u001b[38;5;241m=\u001b[39murl,\n\u001b[1;32m     96\u001b[0m             limit\u001b[38;5;241m=\u001b[39mlimit,\n\u001b[1;32m     97\u001b[0m             op_name\u001b[38;5;241m=\u001b[39moperation_name,\n\u001b[1;32m     98\u001b[0m             query_params\u001b[38;5;241m=\u001b[39mparams,\n\u001b[1;32m     99\u001b[0m             _async\u001b[38;5;241m=\u001b[39masynchronous,\n\u001b[1;32m    100\u001b[0m             _all\u001b[38;5;241m=\u001b[39mget_all,\n\u001b[1;32m    101\u001b[0m             skip_space_project_chk\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    102\u001b[0m         )\n\u001b[1;32m    103\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m WMLClientError \u001b[38;5;28;01mas\u001b[39;00m e:\n", "File \u001b[0;32m/opt/conda/envs/Python-RT24.1/lib/python3.11/site-packages/ibm_watsonx_ai/wml_resource.py:605\u001b[0m, in \u001b[0;36mWMLResource._get_with_or_without_limit\u001b[0;34m(self, url, limit, op_name, summary, pre_defined, revision, skip_space_project_chk, query_params, _async, _all, _filter_func, _silent_response_logging)\u001b[0m\n\u001b[1;32m    597\u001b[0m response_get \u001b[38;5;241m=\u001b[39m request_handler\u001b[38;5;241m.\u001b[39mget(\n\u001b[1;32m    598\u001b[0m     url\u001b[38;5;241m=\u001b[39murl,\n\u001b[1;32m    599\u001b[0m     headers\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_client\u001b[38;5;241m.\u001b[39m_get_headers(),\n\u001b[1;32m    600\u001b[0m     params\u001b[38;5;241m=\u001b[39mparams,\n\u001b[1;32m    601\u001b[0m )\n\u001b[1;32m    603\u001b[0m result \u001b[38;5;241m=\u001b[39m cast(\n\u001b[1;32m    604\u001b[0m     \u001b[38;5;28mdict\u001b[39m,\n\u001b[0;32m--> 605\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_handle_response(\n\u001b[1;32m    606\u001b[0m         \u001b[38;5;241m200\u001b[39m,\n\u001b[1;32m    607\u001b[0m         op_name,\n\u001b[1;32m    608\u001b[0m         response_get,\n\u001b[1;32m    609\u001b[0m         _silent_response_logging\u001b[38;5;241m=\u001b[39m_silent_response_logging,\n\u001b[1;32m    610\u001b[0m     ),\n\u001b[1;32m    611\u001b[0m )\n\u001b[1;32m    612\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresources\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m result:\n", "File \u001b[0;32m/opt/conda/envs/Python-RT24.1/lib/python3.11/site-packages/ibm_watsonx_ai/wml_resource.py:168\u001b[0m, in \u001b[0;36mWMLResource._handle_response\u001b[0;34m(self, expected_status_code, operationName, response, json_response, _silent_response_logging, _field_to_hide)\u001b[0m\n\u001b[1;32m    167\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 168\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m ApiRequestFailure(\n\u001b[1;32m    169\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFailure during \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(operationName),\n\u001b[1;32m    170\u001b[0m         response,\n\u001b[1;32m    171\u001b[0m     )\n", "\u001b[0;31mApiRequestFailure\u001b[0m: Failure during Get available foundation models. (GET https://eu-gb.ml.cloud.ibm.com/ml/v1/foundation_model_specs?version=2025-07-09&space_id=07e9c7d9-bb6e-49e4-8503-94d090a24a86&filters=function_text_generation%2C%21lifecycle_withdrawn%3Aand&limit=200)\nStatus code: 403, body: {\"errors\":[{\"code\":\"no_associated_service_instance_error\",\"message\":\"space_id 07e9c7d9-bb6e-49e4-8503-94d090a24a86 is not associated with a WML instance\",\"more_info\":\"https://cloud.ibm.com/apidocs/watsonx-ai#list-foundation-model-specs\"}],\"trace\":\"38fb913e034eadea849bf9f28b57bc10\",\"status_code\":403}", "\nDuring handling of the above exception, another exception occurred:\n", "\u001b[0;31mWMLClientError\u001b[0m                            Traceback (most recent call last)", "Cell \u001b[0;32mIn[21], line 7\u001b[0m\n\u001b[1;32m      3\u001b[0m messages\u001b[38;5;241m.\u001b[39mappend({ \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrole\u001b[39m\u001b[38;5;124m\"\u001b[39m : \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muser\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m\"\u001b[39m: local_question })\n\u001b[1;32m      5\u001b[0m context \u001b[38;5;241m=\u001b[39m RuntimeContext(api_client\u001b[38;5;241m=\u001b[39mclient, request_payload_json\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m: messages})\n\u001b[0;32m----> 7\u001b[0m response \u001b[38;5;241m=\u001b[39m local_function(context)\n\u001b[1;32m      9\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (streaming):\n", "Cell \u001b[0;32mIn[19], line 111\u001b[0m, in \u001b[0;36mgen_ai_service.<locals>.generate\u001b[0;34m(context)\u001b[0m\n\u001b[1;32m    109\u001b[0m messages \u001b[38;5;241m=\u001b[39m payload\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    110\u001b[0m inner_client \u001b[38;5;241m=\u001b[39m APIClient({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124murl\u001b[39m\u001b[38;5;124m\"\u001b[39m: service_url, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtoken\u001b[39m\u001b[38;5;124m\"\u001b[39m: context\u001b[38;5;241m.\u001b[39mget_token()})\n\u001b[0;32m--> 111\u001b[0m model \u001b[38;5;241m=\u001b[39m create_chat_model(inner_client)\n\u001b[1;32m    112\u001b[0m tools \u001b[38;5;241m=\u001b[39m create_tools(inner_client)\n\u001b[1;32m    113\u001b[0m agent \u001b[38;5;241m=\u001b[39m create_agent(model, tools, messages)\n", "Cell \u001b[0;32mIn[19], line 37\u001b[0m, in \u001b[0;36mgen_ai_service.<locals>.create_chat_model\u001b[0;34m(watsonx_client)\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcreate_chat_model\u001b[39m(watsonx_client):\n\u001b[1;32m     30\u001b[0m     parameters \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m     31\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfrequency_penalty\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m0\u001b[39m,\n\u001b[1;32m     32\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmax_tokens\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m1000\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtop_p\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m     36\u001b[0m     }\n\u001b[0;32m---> 37\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ChatWatsonx(\n\u001b[1;32m     38\u001b[0m         model_id\u001b[38;5;241m=\u001b[39mmodel_id,\n\u001b[1;32m     39\u001b[0m         url\u001b[38;5;241m=\u001b[39mservice_url,\n\u001b[1;32m     40\u001b[0m         space_id\u001b[38;5;241m=\u001b[39mspace_id,\n\u001b[1;32m     41\u001b[0m         params\u001b[38;5;241m=\u001b[39mparameters,\n\u001b[1;32m     42\u001b[0m         watsonx_client\u001b[38;5;241m=\u001b[39mwatsonx_client,\n\u001b[1;32m     43\u001b[0m     )\n", "File \u001b[0;32m/opt/conda/envs/Python-RT24.1/lib/python3.11/site-packages/langchain_core/load/serializable.py:130\u001b[0m, in \u001b[0;36mSerializable.__init__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    128\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs: Any, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    129\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\"\"\"\u001b[39;00m  \u001b[38;5;66;03m# noqa: D419\u001b[39;00m\n\u001b[0;32m--> 130\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n", "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n", "File \u001b[0;32m/opt/conda/envs/Python-RT24.1/lib/python3.11/site-packages/langchain_ibm/chat_models.py:528\u001b[0m, in \u001b[0;36mChatWatsonx.validate_environment\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    526\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Validate that credentials and python package exists in environment.\"\"\"\u001b[39;00m\n\u001b[1;32m    527\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwatsonx_client, APIClient):\n\u001b[0;32m--> 528\u001b[0m     watsonx_model \u001b[38;5;241m=\u001b[39m ModelInference(\n\u001b[1;32m    529\u001b[0m         model_id\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_id,\n\u001b[1;32m    530\u001b[0m         params\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparams,\n\u001b[1;32m    531\u001b[0m         api_client\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwatsonx_client,\n\u001b[1;32m    532\u001b[0m         project_id\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mproject_id,\n\u001b[1;32m    533\u001b[0m         space_id\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mspace_id,\n\u001b[1;32m    534\u001b[0m         verify\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverify,\n\u001b[1;32m    535\u001b[0m     )\n\u001b[1;32m    536\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwatsonx_model \u001b[38;5;241m=\u001b[39m watsonx_model\n\u001b[1;32m    538\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n", "File \u001b[0;32m/opt/conda/envs/Python-RT24.1/lib/python3.11/site-packages/ibm_watsonx_ai/foundation_models/inference/model_inference.py:222\u001b[0m, in \u001b[0;36mModelInference.__init__\u001b[0;34m(self, model_id, deployment_id, params, credentials, project_id, space_id, verify, api_client, validate, persistent_connection, max_retries, delay_time, retry_status_codes)\u001b[0m\n\u001b[1;32m    220\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_inference: BaseModelInference\n\u001b[1;32m    221\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_id:\n\u001b[0;32m--> 222\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_inference \u001b[38;5;241m=\u001b[39m FMModelInference(\n\u001b[1;32m    223\u001b[0m         model_id\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_id,\n\u001b[1;32m    224\u001b[0m         api_client\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_client,\n\u001b[1;32m    225\u001b[0m         params\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparams,\n\u001b[1;32m    226\u001b[0m         validate\u001b[38;5;241m=\u001b[39mvalidate,\n\u001b[1;32m    227\u001b[0m         persistent_connection\u001b[38;5;241m=\u001b[39mpersistent_connection,\n\u001b[1;32m    228\u001b[0m         max_retries\u001b[38;5;241m=\u001b[39mmax_retries,\n\u001b[1;32m    229\u001b[0m         delay_time\u001b[38;5;241m=\u001b[39mdelay_time,\n\u001b[1;32m    230\u001b[0m         retry_status_codes\u001b[38;5;241m=\u001b[39mretry_status_codes,\n\u001b[1;32m    231\u001b[0m     )\n\u001b[1;32m    232\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    233\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdeployment_id \u001b[38;5;241m=\u001b[39m cast(\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdeployment_id)\n", "File \u001b[0;32m/opt/conda/envs/Python-RT24.1/lib/python3.11/site-packages/ibm_watsonx_ai/foundation_models/inference/fm_model_inference.py:71\u001b[0m, in \u001b[0;36mFMModelInference.__init__\u001b[0;34m(self, model_id, api_client, params, validate, persistent_connection, max_retries, delay_time, retry_status_codes)\u001b[0m\n\u001b[1;32m     68\u001b[0m model_specs: \u001b[38;5;28mdict\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m()\n\u001b[1;32m     70\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_client\u001b[38;5;241m.\u001b[39m_use_fm_ga_api:\n\u001b[0;32m---> 71\u001b[0m     model_specs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_client\u001b[38;5;241m.\u001b[39mfoundation_models\u001b[38;5;241m.\u001b[39mget_model_specs()  \u001b[38;5;66;03m# type: ignore[assignment]\u001b[39;00m\n\u001b[1;32m     72\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     73\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m catch_warnings():\n", "File \u001b[0;32m/opt/conda/envs/Python-RT24.1/lib/python3.11/site-packages/ibm_watsonx_ai/foundation_models_manager.py:148\u001b[0m, in \u001b[0;36mFoundationModelsManager.get_model_specs\u001b[0;34m(self, model_id, limit, asynchronous, get_all, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_model_specs\u001b[39m(\n\u001b[1;32m    113\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    114\u001b[0m     model_id: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    118\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[1;32m    119\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mdict\u001b[39m \u001b[38;5;241m|\u001b[39m Generator \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    120\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    121\u001b[0m \u001b[38;5;124;03m    Retrieves a list of specifications for a deployed foundation model.\u001b[39;00m\n\u001b[1;32m    122\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    146\u001b[0m \u001b[38;5;124;03m        client.foundation_models.get_model_specs(model_id=\"google/flan-ul2\")\u001b[39;00m\n\u001b[1;32m    147\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 148\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_spec(\n\u001b[1;32m    149\u001b[0m         url\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_client\u001b[38;5;241m.\u001b[39m_href_definitions\u001b[38;5;241m.\u001b[39mget_fm_specifications_href(),\n\u001b[1;32m    150\u001b[0m         operation_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGet available foundation models\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    151\u001b[0m         error_msg_id\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfm_prompt_tuning_no_model_specs\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    152\u001b[0m         filters\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m    153\u001b[0m             \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    154\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_client\u001b[38;5;241m.\u001b[39mCPD_version \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m5.0\u001b[39m\n\u001b[1;32m    155\u001b[0m             \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfunction_text_generation,!lifecycle_withdrawn:and\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    156\u001b[0m         ),\n\u001b[1;32m    157\u001b[0m         model_id\u001b[38;5;241m=\u001b[39mmodel_id,\n\u001b[1;32m    158\u001b[0m         limit\u001b[38;5;241m=\u001b[39mlimit,\n\u001b[1;32m    159\u001b[0m         asynchronous\u001b[38;5;241m=\u001b[39masynchronous,\n\u001b[1;32m    160\u001b[0m         get_all\u001b[38;5;241m=\u001b[39mget_all,\n\u001b[1;32m    161\u001b[0m         tech_preview\u001b[38;5;241m=\u001b[39mkwargs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtech_preview\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m),\n\u001b[1;32m    162\u001b[0m     )\n", "File \u001b[0;32m/opt/conda/envs/Python-RT24.1/lib/python3.11/site-packages/ibm_watsonx_ai/foundation_models_manager.py:104\u001b[0m, in \u001b[0;36mFoundationModelsManager._get_spec\u001b[0;34m(self, url, operation_name, error_msg_id, model_id, limit, filters, asynchronous, get_all, tech_preview)\u001b[0m\n\u001b[1;32m     94\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_with_or_without_limit(\n\u001b[1;32m     95\u001b[0m             url\u001b[38;5;241m=\u001b[39murl,\n\u001b[1;32m     96\u001b[0m             limit\u001b[38;5;241m=\u001b[39mlimit,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    101\u001b[0m             skip_space_project_chk\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    102\u001b[0m         )\n\u001b[1;32m    103\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m WMLClientError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m--> 104\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m WMLClientError(\n\u001b[1;32m    105\u001b[0m         Messages\u001b[38;5;241m.\u001b[39mget_message(\n\u001b[1;32m    106\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_client\u001b[38;5;241m.\u001b[39mcredentials\u001b[38;5;241m.\u001b[39murl,\n\u001b[1;32m    107\u001b[0m             message_id\u001b[38;5;241m=\u001b[39merror_msg_id,\n\u001b[1;32m    108\u001b[0m         ),\n\u001b[1;32m    109\u001b[0m         e,\n\u001b[1;32m    110\u001b[0m     )\n", "\u001b[0;31mWMLClientError\u001b[0m: Unable to get model specifications from url: https://eu-gb.ml.cloud.ibm.com\nReason: Failure during Get available foundation models. (GET https://eu-gb.ml.cloud.ibm.com/ml/v1/foundation_model_specs?version=2025-07-09&space_id=07e9c7d9-bb6e-49e4-8503-94d090a24a86&filters=function_text_generation%2C%21lifecycle_withdrawn%3Aand&limit=200)\nStatus code: 403, body: {\"errors\":[{\"code\":\"no_associated_service_instance_error\",\"message\":\"space_id 07e9c7d9-bb6e-49e4-8503-94d090a24a86 is not associated with a WML instance\",\"more_info\":\"https://cloud.ibm.com/apidocs/watsonx-ai#list-foundation-model-specs\"}],\"trace\":\"38fb913e034eadea849bf9f28b57bc10\",\"status_code\":403}"], "ename": "WMLClientError", "evalue": "Unable to get model specifications from url: https://eu-gb.ml.cloud.ibm.com\nReason: Failure during Get available foundation models. (GET https://eu-gb.ml.cloud.ibm.com/ml/v1/foundation_model_specs?version=2025-07-09&space_id=07e9c7d9-bb6e-49e4-8503-94d090a24a86&filters=function_text_generation%2C%21lifecycle_withdrawn%3Aand&limit=200)\nStatus code: 403, body: {\"errors\":[{\"code\":\"no_associated_service_instance_error\",\"message\":\"space_id 07e9c7d9-bb6e-49e4-8503-94d090a24a86 is not associated with a WML instance\",\"more_info\":\"https://cloud.ibm.com/apidocs/watsonx-ai#list-foundation-model-specs\"}],\"trace\":\"38fb913e034eadea849bf9f28b57bc10\",\"status_code\":403}", "output_type": "error"}], "execution_count": 21}, {"cell_type": "markdown", "source": "## 3. Store and deploy the AI Service\nBefore you can deploy the AI Service, you must store the AI service in your watsonx.ai repository.", "metadata": {}}, {"cell_type": "code", "source": "# Look up software specification for the AI service\nsoftware_spec_id_in_project = \"45f12dfe-aa78-5b8d-9f38-0ee223c47309\"\nsoftware_spec_id = \"\"\n\ntry:\n    software_spec_id = client.software_specifications.get_id_by_name(\"runtime-24.1-py3.11\")\nexcept:\n    software_spec_id = client.spaces.promote(software_spec_id_in_project, source_project_id, space_id)", "metadata": {"id": "d524fbe3-c9ce-4b48-9cc2-37f0ac089068"}, "outputs": [], "execution_count": null}, {"cell_type": "code", "source": "# Define the request and response schemas for the AI service\nrequest_schema = {\n    \"application/json\": {\n        \"$schema\": \"http://json-schema.org/draft-07/schema#\",\n        \"type\": \"object\",\n        \"properties\": {\n            \"messages\": {\n                \"title\": \"The messages for this chat session.\",\n                \"type\": \"array\",\n                \"items\": {\n                    \"type\": \"object\",\n                    \"properties\": {\n                        \"role\": {\n                            \"title\": \"The role of the message author.\",\n                            \"type\": \"string\",\n                            \"enum\": [\"user\",\"assistant\"]\n                        },\n                        \"content\": {\n                            \"title\": \"The contents of the message.\",\n                            \"type\": \"string\"\n                        }\n                    },\n                    \"required\": [\"role\",\"content\"]\n                }\n            }\n        },\n        \"required\": [\"messages\"]\n    }\n}\n\nresponse_schema = {\n    \"application/json\": {\n        \"oneOf\": [{\"$schema\":\"http://json-schema.org/draft-07/schema#\",\"type\":\"object\",\"description\":\"AI Service response for /ai_service_stream\",\"properties\":{\"choices\":{\"description\":\"A list of chat completion choices.\",\"type\":\"array\",\"items\":{\"type\":\"object\",\"properties\":{\"index\":{\"type\":\"integer\",\"title\":\"The index of this result.\"},\"delta\":{\"description\":\"A message result.\",\"type\":\"object\",\"properties\":{\"content\":{\"description\":\"The contents of the message.\",\"type\":\"string\"},\"role\":{\"description\":\"The role of the author of this message.\",\"type\":\"string\"}},\"required\":[\"role\"]}}}}},\"required\":[\"choices\"]},{\"$schema\":\"http://json-schema.org/draft-07/schema#\",\"type\":\"object\",\"description\":\"AI Service response for /ai_service\",\"properties\":{\"choices\":{\"description\":\"A list of chat completion choices\",\"type\":\"array\",\"items\":{\"type\":\"object\",\"properties\":{\"index\":{\"type\":\"integer\",\"description\":\"The index of this result.\"},\"message\":{\"description\":\"A message result.\",\"type\":\"object\",\"properties\":{\"role\":{\"description\":\"The role of the author of this message.\",\"type\":\"string\"},\"content\":{\"title\":\"Message content.\",\"type\":\"string\"}},\"required\":[\"role\"]}}}}},\"required\":[\"choices\"]}]\n    }\n}", "metadata": {"id": "6594130a-4505-4abb-a232-703e51d9f643"}, "outputs": [], "execution_count": null}, {"cell_type": "code", "source": "# Store the AI service in the repository\nai_service_metadata = {\n    client.repository.AIServiceMetaNames.NAME: \"Career Counseling \",\n    client.repository.AIServiceMetaNames.DESCRIPTION: \"\",\n    client.repository.AIServiceMetaNames.SOFTWARE_SPEC_ID: software_spec_id,\n    client.repository.AIServiceMetaNames.CUSTOM: {},\n    client.repository.AIServiceMetaNames.REQUEST_DOCUMENTATION: request_schema,\n    client.repository.AIServiceMetaNames.RESPONSE_DOCUMENTATION: response_schema,\n    client.repository.AIServiceMetaNames.TAGS: [\"wx-agent\"]\n}\n\nai_service_details = client.repository.store_ai_service(meta_props=ai_service_metadata, ai_service=gen_ai_service)", "metadata": {"id": "11cb038e-3d73-4430-9d2c-01b94dc825ed"}, "outputs": [], "execution_count": null}, {"cell_type": "code", "source": "# Get the AI Service ID\n\nai_service_id = client.repository.get_ai_service_id(ai_service_details)", "metadata": {"id": "d04d55c5-e696-4719-801b-74c95d2ea8f2"}, "outputs": [], "execution_count": null}, {"cell_type": "code", "source": "# Deploy the stored AI Service\ndeployment_custom = {\n    \"avatar_icon\": \"ChatBot\",\n    \"avatar_color\": \"backgroundBrand\",\n    \"placeholder_image\": \"placeholder5.png\"\n}\ndeployment_metadata = {\n    client.deployments.ConfigurationMetaNames.NAME: \"Career Counseling \",\n    client.deployments.ConfigurationMetaNames.ONLINE: {},\n    client.deployments.ConfigurationMetaNames.CUSTOM: deployment_custom,\n    client.deployments.ConfigurationMetaNames.DESCRIPTION: \"You can ask any question regarding your career counseling.\",\n    client.repository.AIServiceMetaNames.TAGS: [\"wx-agent\"]\n}\n\nfunction_deployment_details = client.deployments.create(ai_service_id, meta_props=deployment_metadata, space_id=space_id)\n", "metadata": {"id": "75956ffc-d3fb-401f-a801-d4ae01b2b655"}, "outputs": [], "execution_count": null}, {"cell_type": "markdown", "source": "## 4. Test AI Service", "metadata": {}}, {"cell_type": "code", "source": "# Get the ID of the AI Service deployment just created\n\ndeployment_id = client.deployments.get_id(function_deployment_details)\nprint(deployment_id)", "metadata": {"id": "5b0d9019-d7cd-406b-9207-d012445d8f9b"}, "outputs": [], "execution_count": null}, {"cell_type": "code", "source": "messages = []\nremote_question = \"Change this question to test your function\"\nmessages.append({ \"role\" : \"user\", \"content\": remote_question })\npayload = { \"messages\": messages }", "metadata": {"id": "153306eb-c999-4e5a-933f-9bf02dd0d0af"}, "outputs": [], "execution_count": null}, {"cell_type": "code", "source": "result = client.deployments.run_ai_service(deployment_id, payload)\nif \"error\" in result:\n    print(result[\"error\"])\nelse:\n    print(result)", "metadata": {"id": "4c84cdad-7d59-4106-9f39-48561bed97e2"}, "outputs": [], "execution_count": null}, {"cell_type": "markdown", "source": "# Next steps\nYou successfully deployed and tested the AI Service! You can now view\nyour deployment and test it as a REST API endpoint.\n\n<a id=\"copyrights\"></a>\n### Copyrights\n\nLicensed Materials - Copyright \u00a9 2024 IBM. This notebook and its source code are released under the terms of the ILAN License.\nUse, duplication disclosure restricted by GSA ADP Schedule Contract with IBM Corp.\n\n**Note:** The auto-generated notebooks are subject to the International License Agreement for Non-Warranted Programs (or equivalent) and License Information document for watsonx.ai Auto-generated Notebook (License Terms), such agreements located in the link below. Specifically, the Source Components and Sample Materials clause included in the License Information document for watsonx.ai Studio Auto-generated Notebook applies to the auto-generated notebooks.  \n\nBy downloading, copying, accessing, or otherwise using the materials, you agree to the <a href=\"https://www14.software.ibm.com/cgi-bin/weblap/lap.pl?li_formnum=L-AMCU-BYC7LF\" target=\"_blank\">License Terms</a>  ", "metadata": {}}]}